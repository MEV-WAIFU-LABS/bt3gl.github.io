<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>chmod +x singularity.sh</title><link href="http://singularity.miavonsteinkirch.com/" rel="alternate"></link><link href="http://singularity.miavonsteinkirch.com/feeds/ios-arkit-ar.atom.xml" rel="self"></link><id>http://singularity.miavonsteinkirch.com/</id><updated>2016-12-16T00:00:00-05:00</updated><entry><title>Quick &amp; Dirty iOS ARKit with "Post Malone Balloon"</title><link href="http://singularity.miavonsteinkirch.com/quick-dirty-ios-arkit-with-post-malone-balloon.html" rel="alternate"></link><updated>2016-12-16T00:00:00-05:00</updated><author><name>Mia Steinkirch</name></author><id>tag:singularity.miavonsteinkirch.com,2016-12-16:quick-dirty-ios-arkit-with-post-malone-balloon.html</id><summary type="html">&lt;p&gt;&lt;img alt="cyberpunk" height="300px" src="./cyberpunk/post_1.jpg" width="400px" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Augmented reality (AR) describes user experiences that add 2D or 3D elements to the live view from a device’s camera in a way that makes those elements appear to inhabit the real world.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hi Everyone!&lt;/p&gt;
&lt;p&gt;In this post, I show how neat is to write an AR iOS application with &lt;a href="https://developer.apple.com/arkit/"&gt;ARKit&lt;/a&gt;, a framework that provides you high-level classes for &lt;strong&gt;tracking&lt;/strong&gt;, &lt;strong&gt;scene understanding&lt;/strong&gt;, and &lt;strong&gt;rendering&lt;/strong&gt;. More specifically, ARKit is a session-based framework. This means that everything will happen in a concrete session. Sessions are a way of encapsulating the logic and data contained within a defined period of the applications activity. It relates the virtual objects with the real world by means of the Tracking.&lt;/p&gt;
&lt;p&gt;This app runs an ARKit world tracking session with content displayed in a &lt;a href="https://developer.apple.com/documentation/spriteKit"&gt;SpriteKit&lt;/a&gt; 2D view. Every session has a scene that will render the virtual objects in the real world, accessed using the iOS device sensors.&lt;/p&gt;
&lt;p&gt;But, before everything, I recommend you to watch &lt;a href="https://developer.apple.com/videos/play/wwdc2017/602/"&gt;WWDC 2017's 'Introducing ARKit: Augmented Reality for iOS'&lt;/a&gt;. It gives a nice overview of ARKit's capabilities.&lt;/p&gt;
&lt;p&gt;Ah, btw, the source code for this project is &lt;a href="https://github.com/mvonsteinkirch/AR_PostMalone"&gt;available for you at github&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;The source code for AR_PostMalone the following structure:&lt;/h2&gt;
&lt;h3&gt;&lt;code&gt;Info.plist&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;An information property list file is an XML file that contains essential configuration information for a bundled executable. Example of the information you want to add is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The name of your app (&lt;code&gt;&amp;lt;string&amp;gt;PostMaloneBalloon&amp;lt;/string&amp;gt;&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Camera usage (&lt;code&gt;&amp;lt;key&amp;gt;NSCameraUsageDescription&amp;lt;/key&amp;gt;&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Frameworks you need (&lt;code&gt;&amp;lt;key&amp;gt;UIRequiredDeviceCapabilities&amp;lt;/key&amp;gt;&lt;/code&gt; with &lt;code&gt;&amp;lt;string&amp;gt;armv7&amp;lt;/string&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;string&amp;gt;arkit&amp;lt;/string&amp;gt;&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;code&gt;Assets.xcassets&lt;/code&gt; directory&lt;/h3&gt;
&lt;p&gt;Where you place assets such as the images used in your App (Post Malone head) and icons. A file &lt;code&gt;Content.json&lt;/code&gt; is placed inside every directory to describe the assets.&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;Base.lproj&lt;/code&gt; directory&lt;/h3&gt;
&lt;p&gt;Contains two &lt;a href="https://www.raywenderlich.com/160521/storyboards-tutorial-ios-11-part-1"&gt;story board files&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;LaunchScreen.storyboard&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Main.storyboard&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;code&gt;Scene.swift&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Anchors are 3D points that correspond to real-world features that ARKit detects. Anchors are created in this class, together with the Sprite scene (Scene.sks). The class &lt;code&gt;Scene&lt;/code&gt; controls how the App is operating within the scenes. Rendering brings tracking and scene understanding together with your content.&lt;/p&gt;
&lt;p&gt;For our App, we are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Defining the method &lt;code&gt;touchesBegan&lt;/code&gt;, where we define what happens when we click the scene.&lt;/li&gt;
&lt;li&gt;The sequence of movements is defined by &lt;code&gt;let sequence = SKAction.sequence([popSound, moveDown, moveDownFloating, moveToBottom])&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;When you touch the scene, a Post Malone Balloon head appears and starts to behave as a balloon (&lt;code&gt;moveDownFloating = ((arc4random() % 2)==0) ? moveLeftDown : moveRightDown&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;The balloon either pops (&lt;code&gt;let popSound = SKAction.playSoundFileNamed("pop", waitForCompletion: false)&lt;/code&gt;) or fades after a second (&lt;code&gt;fadeOut = SKAction.fadeOut(withDuration: 1.0)&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;An ARAnchor uses a 4×4 matrix that represents the combined position, rotation or orientation, and scale of an object in three-dimensional space (as in &lt;code&gt;var translation = matrix_identity_float4x4&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;code&gt;ViewController.swift&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This view is managed by the class ViewController, which inherits from &lt;code&gt;ARSKViewDelegate&lt;/code&gt; so that we can create a &lt;code&gt;sceneView&lt;/code&gt; variable. This class has methods for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Views&lt;/li&gt;
&lt;li&gt;Scaling and placing the view.&lt;/li&gt;
&lt;li&gt;View when it loads (and load the pre-defined scene from &lt;a href="https://developer.apple.com/documentation/spritekit/skscene"&gt;SKScene&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;View to appear and disappear.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sessions&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Session interrupted.&lt;/li&gt;
&lt;li&gt;Session ended.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;code&gt;AppDelegate.swift&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This is where we call the class &lt;code&gt;AppDelegate&lt;/code&gt;, which responds for &lt;code&gt;UIApplicationMain&lt;/code&gt;. In this class, we create a variable that will work as the window UI, and we have UI methods for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;See if the application is about to move from active to inactive state (for example, pause ongoing tasks).&lt;/li&gt;
&lt;li&gt;Release shared resources and save user data.&lt;/li&gt;
&lt;li&gt;Change from the background to the active state.&lt;/li&gt;
&lt;li&gt;Restart any tasks that were paused while the application was inactive.&lt;/li&gt;
&lt;li&gt;Termination actions for when the application is about to terminate (for example, to save data if appropriate).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Some Terminology&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Field of view&lt;/strong&gt;: measured in degrees, is the extent of the observable world that is seen at any given moment (humans have a FOV of around 180°, but most HMDs offer between 50 and 110°).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt;: In VR, a 20-millisecond latency is considered low and acceptable for a comfortable experience.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Haptics&lt;/strong&gt;: recreate the sense of touch by applying forces, vibrations, or motions to the user, through feedback devices (example, vibrating game controllers).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Stitching&lt;/strong&gt;: the process of combining multiple video sources with overlapping fields of view to produce a fully immersive 360°. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Visual Inertial Odometry&lt;/strong&gt;: ARKit analyzes the phone camera and motion data in order to keep track of the world around the
ARSession object that manages the motion tracking and image processing.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary></entry></feed>