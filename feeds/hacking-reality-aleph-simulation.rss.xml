<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>chmod +x singularity.sh</title><link>http://bt3gl.github.io/</link><description></description><atom:link href="http://bt3gl.github.io/feeds/hacking-reality-aleph-simulation.rss.xml" rel="self"></atom:link><lastBuildDate>Sat, 15 Nov 2014 04:22:00 -0500</lastBuildDate><item><title>Fun with Genetic Algorithms</title><link>http://bt3gl.github.io/fun-with-genetic-algorithms.html</link><description>&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=6j_3MuyEMt0"&gt;&lt;img alt="hacking" height="300px" src="./cyberpunk/h1.png" width="400px" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Natural selection is the world optimizing for survival on Earth. Every life form on Earth is a solution generated by evolution's algorithm, which evolves a population of individuals over generations, optimizing for survival. This is a way to describe this algorithm:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The algorithm begins by creating a random initial population.&lt;/li&gt;
&lt;li&gt;Select the fittest individuals to be the parents of the next generation (a score). Randomly select some of the non-fittest individuals to be parents as well, increasing the chance of finding a global optimum.&lt;/li&gt;
&lt;li&gt;Crossover the selected parents, creating new individuals. There will be a chance that the child will have a random mutation of its numbers.&lt;/li&gt;
&lt;li&gt;Calculate the average population fitness. Rinse and repeat.&lt;/li&gt;
&lt;li&gt;When the average population fitness is ~0 (or close to it), stop evolving.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is the pseudocode:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;START&lt;/span&gt;
&lt;span class="n"&gt;Generate&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;initial&lt;/span&gt; &lt;span class="n"&gt;population&lt;/span&gt;
&lt;span class="n"&gt;Compute&lt;/span&gt; &lt;span class="n"&gt;fitness&lt;/span&gt;
&lt;span class="n"&gt;REPEAT&lt;/span&gt;
    &lt;span class="n"&gt;Selection&lt;/span&gt;
    &lt;span class="n"&gt;Crossover&lt;/span&gt;
    &lt;span class="n"&gt;Mutation&lt;/span&gt;
    &lt;span class="n"&gt;Compute&lt;/span&gt; &lt;span class="n"&gt;fitness&lt;/span&gt;
&lt;span class="n"&gt;UNTIL&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;population&lt;/span&gt; &lt;span class="n"&gt;has&lt;/span&gt; &lt;span class="n"&gt;converged&lt;/span&gt;
&lt;span class="n"&gt;STOP&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Genetic_algorithm"&gt;GA algorithm are known for decades&lt;/a&gt;, but they are still &lt;em&gt;fun&lt;/em&gt; as an optimization technique. Combined with neural networks they can help to find the best hyper-parameters, by creating a population of many NNs and letting it evolve.&lt;/p&gt;
&lt;h2&gt;This w33k's References&lt;/h2&gt;
&lt;h3&gt;Papers&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.simulation-argument.com/simulation.pdf"&gt;Are You Living in a Simulation, Nick Bostrom&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1903.04951.pdf"&gt;AdS/CFT as a deep Boltzmann machine&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Books&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/Complexity-Guided-Tour-Melanie-Mitchell/dp/0199798109"&gt;Complexity: A Guided Tour&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.com/New-Kind-Science-Stephen-Wolfram/dp/1579550088/"&gt;A New Kind of Science&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Thinking&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://web.mit.edu/allanmc/www/borgesaleph.pdf"&gt;The Aleph, by Borges&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Mia Steinkirch</dc:creator><pubDate>Sat, 15 Nov 2014 04:22:00 -0500</pubDate><guid>tag:bt3gl.github.io,2014-11-15:fun-with-genetic-algorithms.html</guid><category></category></item></channel></rss>